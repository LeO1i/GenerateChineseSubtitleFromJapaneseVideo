## Japanese Video Subtitle Generator

Generate Chinese subtitles from a Japanese video using OpenAI Whisper, optionally review/edit the SRT, and burn the subtitles back into the video with FFmpeg.

### Features
- Automatic speech recognition (Japanese → text) using Whisper
- Automatic translation (Japanese → Chinese) via Google Translate
- SRT generation with better line breaking and timing
- Two-step workflow:
  1) Generate SRT and review/edit
  2) Burn the SRT into the video (hard-sub)
- One-click legacy flow still available inside the code if needed

### Requirements
- Python 3.9+ (64-bit recommended)
- FFmpeg installed locally and accessible at a known path
- Internet access for Google Translate

### Install
1) Create a virtual environment (PowerShell on Windows):
```powershell
python -m venv .venv
.\.venv\Scripts\Activate.ps1
```

2) Install PyTorch
- CPU (simple):
```powershell
pip install torch --index-url https://download.pytorch.org/whl/cpu
```
- GPU (CUDA): follow the official selector at [PyTorch Get Started](https://pytorch.org/get-started/locally/), for example (replace cu121 accordingly):
```powershell
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

3) Install project dependencies:
```powershell
pip install -r requirements.txt
```

4) Install FFmpeg (Windows)
- Download a static build from [FFmpeg official site](https://ffmpeg.org/download.html) or a trusted mirror
- Extract to: `C:\ffmpeg\ffmpeg-master-latest-win64-gpl\` (to match the default path in code), or
- Put `ffmpeg.exe` on your PATH and then update the hardcoded paths in the code to just `ffmpeg`

Update these two places if your FFmpeg path differs:
- `write_sutitle.py`: variable `ffmpeg_bin`
- `speech_extract.py`: in `extract_audio(...)` command list

### Usage
Run the interactive program:
```powershell
python main.py
```

You will be asked:
- If you already have an SRT generated by this program
  - If yes: provide the SRT path and the video path to burn directly
  - If no: provide only the video path; the app will generate an SRT first

Typical flow (recommended):
1) Choose “n” when asked if you already have an SRT
2) Provide the Japanese video path
3) Wait for transcription and translation; SRT will be saved next to the video (e.g. `yourvideo_chinese.srt`)
4) Open and review/edit the SRT in any subtitle editor or text editor
5) When prompted, choose “y” to burn the reviewed SRT into a new video (e.g. `yourvideo_cn_hardsub.mp4`)

### Notes
- The app auto-detects CUDA. If no CUDA toolkit/driver is available, it will run on CPU (slower). To enable GPU, install the CUDA-enabled PyTorch build.
- Ensure your SRT is saved as UTF-8. The FFmpeg filter is configured with `charenc=UTF-8`.
- Subtitle style can be tweaked in `write_sutitle.py` via `force_style` (font, size, outline, margin).

### Project Structure
- `main.py`: CLI entry. Guides the two-step workflow (generate → review → burn)
- `speech_extract.py`: Core pipeline (audio extraction, Whisper transcription, translation, SRT writing)
- `write_sutitle.py`: Burns SRT into video using FFmpeg

### Troubleshooting
- FFmpeg not found / path errors:
  - Verify the `ffmpeg_bin` path in `write_sutitle.py` and the path in `speech_extract.py` → `extract_audio(...)`
  - Try running `ffmpeg -version` in your shell to confirm it’s on PATH
- Slow performance:
  - Running on CPU is much slower. Install a CUDA build of PyTorch if you have a compatible NVIDIA GPU
- Google Translate fails intermittently:
  - The `googletrans` library uses an unofficial API and may throttle. You can rerun or add your own translation backend if needed

### License
For personal/educational use. Check licenses of third-party tools (Whisper, PyTorch, FFmpeg, Google Translate) before commercial use.


